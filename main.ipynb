{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "21c356f8",
      "metadata": {},
      "source": [
        "# Projeto: Rede Neural Artificial para Detecção de Fraudes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6aecf653",
      "metadata": {},
      "source": [
        "## 1) Introdução\n",
        "\n",
        "Este notebook demonstra o desenvolvimento de uma Rede Neural Artificial com dois focos:\n",
        "\n",
        "1. **CNN em CIFAR-10**: exemplo clássico de boas práticas em visão computacional.\n",
        "2. **MLP em fraude tabular**: problema real de detecção de fraude, caracterizado por dados desbalanceados (~1% positivos) e custo assimétrico.\n",
        "\n",
        "A arquitetura e as justificativas seguem literatura especializada e boas práticas (Goodfellow et al., 2016; Srivastava et al., 2014; He et al., 2016)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90c9210d",
      "metadata": {},
      "source": [
        "## 2) CNN em CIFAR-10\n",
        "\n",
        "Nesta seção treinamos uma CNN VGG-like com BatchNorm, Dropout, L2, GlobalAveragePooling e augmentation leve.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef016c73",
      "metadata": {},
      "source": [
        "### 2.1 Carregamento e Pré-processamento dos Dados\n",
        "\n",
        "Carregamos o **dataset CIFAR-10**, composto por 60 mil imagens coloridas (32×32, 3 canais) distribuídas em 10 classes.  \n",
        "- Divisão: 50 mil imagens para treino e 10 mil para teste.  \n",
        "- As labels são convertidas para **one-hot encoding** com `to_categorical`.  \n",
        "- As imagens são **normalizadas** para o intervalo [0,1], facilitando a convergência da rede.  \n",
        "- Por fim, conferimos os formatos de entrada e saída resultantes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6d9b5fa3",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((50000, 32, 32, 3), (50000, 10))"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "(num_classes, input_shape) = (10, (32, 32, 3))\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "y_train, y_test = to_categorical(y_train, num_classes), to_categorical(y_test, num_classes)\n",
        "x_train, x_test = x_train/255.0, x_test/255.0\n",
        "x_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b71e6485",
      "metadata": {},
      "source": [
        "### 2.2 Definição da Arquitetura da CNN\n",
        "\n",
        "Aqui implementamos uma **CNN do tipo VGG-like** para o CIFAR-10, seguindo boas práticas:  \n",
        "- **Camadas convolucionais** com kernel 3×3 e ativação ReLU para extração de padrões locais.  \n",
        "- **Batch Normalization** após cada convolução para estabilizar o treino e acelerar a convergência.  \n",
        "- **MaxPooling (2×2)** para reduzir dimensionalidade e capturar características hierárquicas.  \n",
        "- **Dropout progressivo (0.25 → 0.45 → 0.5)** para mitigar overfitting.  \n",
        "- **Regularização L2 (1e-4)** aplicada aos pesos.  \n",
        "- **GlobalAveragePooling2D** em vez de Flatten, reduzindo número de parâmetros.  \n",
        "- **Camada densa final (128 neurônios, ReLU)** seguida da saída softmax (10 classes).  \n",
        "\n",
        "O modelo é compilado com **Adam (lr=1e-3)** e perda de **categorical crossentropy**, monitorando **acurácia**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "70c63ff9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m147,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">306,602</span> (1.17 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m306,602\u001b[0m (1.17 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">305,706</span> (1.17 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m305,706\u001b[0m (1.17 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "\n",
        "def make_cnn(input_shape, num_classes):\n",
        "    reg = regularizers.l2(1e-4)\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(32, (3,3), padding=\"same\", activation=\"relu\", kernel_regularizer=reg)(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(32, (3,3), padding=\"same\", activation=\"relu\", kernel_regularizer=reg)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "    x = layers.Dropout(0.25)(x)\n",
        "\n",
        "    x = layers.Conv2D(64, (3,3), padding=\"same\", activation=\"relu\", kernel_regularizer=reg)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(64, (3,3), padding=\"same\", activation=\"relu\", kernel_regularizer=reg)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "    x = layers.Dropout(0.35)(x)\n",
        "\n",
        "    x = layers.Conv2D(128, (3,3), padding=\"same\", activation=\"relu\", kernel_regularizer=reg)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(128, (3,3), padding=\"same\", activation=\"relu\", kernel_regularizer=reg)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "    x = layers.Dropout(0.45)(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(128, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "    return models.Model(inputs, outputs)\n",
        "\n",
        "cnn = make_cnn(input_shape, num_classes)\n",
        "cnn.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "            loss=\"categorical_crossentropy\",\n",
        "            metrics=[\"accuracy\"])\n",
        "cnn.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca4dca71",
      "metadata": {},
      "source": [
        "### 2.3 Treinamento com Data Augmentation e Callbacks\n",
        "\n",
        "Nesta etapa, aplicamos **data augmentation** para aumentar a robustez do modelo:  \n",
        "- rotações leves (até 5°),  \n",
        "- flips horizontais,  \n",
        "- deslocamentos de até 10% em largura/altura.  \n",
        "\n",
        "Isso ajuda a CNN a **generalizar melhor** evitando overfitting.  \n",
        "\n",
        "O treinamento utiliza **callbacks**:  \n",
        "- *EarlyStopping*: interrompe se não houver melhora na validação, restaurando os melhores pesos,  \n",
        "- *ReduceLROnPlateau*: reduz a taxa de aprendizado quando o progresso estagna,  \n",
        "- *ModelCheckpoint*: salva o melhor modelo durante o treino.  \n",
        "\n",
        "A rede é treinada por até **50 épocas**, mas pode parar antes se a convergência estabilizar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "cca394f1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/luccahiratsuca/Github/teste/Ponderada-CNN-s/env/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 78ms/step - accuracy: 0.4240 - loss: 1.6280 - val_accuracy: 0.5444 - val_loss: 1.3050 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 80ms/step - accuracy: 0.5719 - loss: 1.2567 - val_accuracy: 0.6145 - val_loss: 1.1359 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 80ms/step - accuracy: 0.6323 - loss: 1.1032 - val_accuracy: 0.6721 - val_loss: 0.9864 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 80ms/step - accuracy: 0.6723 - loss: 1.0109 - val_accuracy: 0.6584 - val_loss: 1.0921 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 83ms/step - accuracy: 0.7016 - loss: 0.9501 - val_accuracy: 0.6785 - val_loss: 1.0461 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 80ms/step - accuracy: 0.7193 - loss: 0.9132 - val_accuracy: 0.7238 - val_loss: 0.8969 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 81ms/step - accuracy: 0.7355 - loss: 0.8793 - val_accuracy: 0.7429 - val_loss: 0.8342 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 82ms/step - accuracy: 0.7441 - loss: 0.8589 - val_accuracy: 0.7296 - val_loss: 0.9248 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 80ms/step - accuracy: 0.7571 - loss: 0.8344 - val_accuracy: 0.7768 - val_loss: 0.7791 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 81ms/step - accuracy: 0.7640 - loss: 0.8181 - val_accuracy: 0.7863 - val_loss: 0.7644 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 82ms/step - accuracy: 0.7690 - loss: 0.8080 - val_accuracy: 0.7802 - val_loss: 0.7658 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 82ms/step - accuracy: 0.7752 - loss: 0.7991 - val_accuracy: 0.7573 - val_loss: 0.8462 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 83ms/step - accuracy: 0.7798 - loss: 0.7844 - val_accuracy: 0.7751 - val_loss: 0.8391 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 82ms/step - accuracy: 0.7817 - loss: 0.7806 - val_accuracy: 0.7764 - val_loss: 0.8064 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 81ms/step - accuracy: 0.7854 - loss: 0.7760 - val_accuracy: 0.8123 - val_loss: 0.6887 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 82ms/step - accuracy: 0.7899 - loss: 0.7646 - val_accuracy: 0.7300 - val_loss: 0.9907 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 84ms/step - accuracy: 0.7944 - loss: 0.7575 - val_accuracy: 0.8224 - val_loss: 0.6677 - learning_rate: 0.0010\n",
            "Epoch 18/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 84ms/step - accuracy: 0.7949 - loss: 0.7550 - val_accuracy: 0.7577 - val_loss: 0.8774 - learning_rate: 0.0010\n",
            "Epoch 19/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 81ms/step - accuracy: 0.7970 - loss: 0.7533 - val_accuracy: 0.7628 - val_loss: 0.8774 - learning_rate: 0.0010\n",
            "Epoch 20/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 83ms/step - accuracy: 0.7995 - loss: 0.7466 - val_accuracy: 0.7799 - val_loss: 0.8223 - learning_rate: 0.0010\n",
            "Epoch 21/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 81ms/step - accuracy: 0.8041 - loss: 0.7417 - val_accuracy: 0.8015 - val_loss: 0.7431 - learning_rate: 0.0010\n",
            "Epoch 22/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 82ms/step - accuracy: 0.8048 - loss: 0.7385 - val_accuracy: 0.8078 - val_loss: 0.7278 - learning_rate: 0.0010\n",
            "Epoch 23/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 83ms/step - accuracy: 0.8200 - loss: 0.6857 - val_accuracy: 0.8136 - val_loss: 0.7188 - learning_rate: 5.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 83ms/step - accuracy: 0.8277 - loss: 0.6578 - val_accuracy: 0.8498 - val_loss: 0.5942 - learning_rate: 5.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 83ms/step - accuracy: 0.8324 - loss: 0.6453 - val_accuracy: 0.8269 - val_loss: 0.6693 - learning_rate: 5.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 83ms/step - accuracy: 0.8312 - loss: 0.6437 - val_accuracy: 0.8382 - val_loss: 0.6365 - learning_rate: 5.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 81ms/step - accuracy: 0.8356 - loss: 0.6269 - val_accuracy: 0.8326 - val_loss: 0.6290 - learning_rate: 5.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 83ms/step - accuracy: 0.8351 - loss: 0.6281 - val_accuracy: 0.8485 - val_loss: 0.5872 - learning_rate: 5.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 83ms/step - accuracy: 0.8369 - loss: 0.6202 - val_accuracy: 0.8360 - val_loss: 0.6349 - learning_rate: 5.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 81ms/step - accuracy: 0.8365 - loss: 0.6191 - val_accuracy: 0.8398 - val_loss: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 83ms/step - accuracy: 0.8411 - loss: 0.6103 - val_accuracy: 0.8470 - val_loss: 0.5863 - learning_rate: 5.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 84ms/step - accuracy: 0.8404 - loss: 0.6072 - val_accuracy: 0.8397 - val_loss: 0.6078 - learning_rate: 5.0000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 86ms/step - accuracy: 0.8412 - loss: 0.6066 - val_accuracy: 0.8298 - val_loss: 0.6611 - learning_rate: 5.0000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 83ms/step - accuracy: 0.8418 - loss: 0.6001 - val_accuracy: 0.8306 - val_loss: 0.6454 - learning_rate: 5.0000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 81ms/step - accuracy: 0.8441 - loss: 0.5986 - val_accuracy: 0.8278 - val_loss: 0.6651 - learning_rate: 5.0000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 313ms/step - accuracy: 0.8423 - loss: 0.5963 - val_accuracy: 0.8387 - val_loss: 0.6241 - learning_rate: 5.0000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 83ms/step - accuracy: 0.8515 - loss: 0.5676 - val_accuracy: 0.8596 - val_loss: 0.5629 - learning_rate: 2.5000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 83ms/step - accuracy: 0.8556 - loss: 0.5530 - val_accuracy: 0.8568 - val_loss: 0.5583 - learning_rate: 2.5000e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 84ms/step - accuracy: 0.8581 - loss: 0.5452 - val_accuracy: 0.8585 - val_loss: 0.5519 - learning_rate: 2.5000e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 81ms/step - accuracy: 0.8563 - loss: 0.5481 - val_accuracy: 0.8608 - val_loss: 0.5486 - learning_rate: 2.5000e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 84ms/step - accuracy: 0.8604 - loss: 0.5381 - val_accuracy: 0.8445 - val_loss: 0.5896 - learning_rate: 2.5000e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 82ms/step - accuracy: 0.8607 - loss: 0.5324 - val_accuracy: 0.8586 - val_loss: 0.5403 - learning_rate: 2.5000e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 82ms/step - accuracy: 0.8617 - loss: 0.5312 - val_accuracy: 0.8653 - val_loss: 0.5333 - learning_rate: 2.5000e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 82ms/step - accuracy: 0.8612 - loss: 0.5288 - val_accuracy: 0.8483 - val_loss: 0.5740 - learning_rate: 2.5000e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 82ms/step - accuracy: 0.8636 - loss: 0.5237 - val_accuracy: 0.8437 - val_loss: 0.6100 - learning_rate: 2.5000e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 80ms/step - accuracy: 0.8651 - loss: 0.5156 - val_accuracy: 0.8514 - val_loss: 0.5836 - learning_rate: 2.5000e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 81ms/step - accuracy: 0.8633 - loss: 0.5171 - val_accuracy: 0.8523 - val_loss: 0.5678 - learning_rate: 2.5000e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 84ms/step - accuracy: 0.8649 - loss: 0.5159 - val_accuracy: 0.8643 - val_loss: 0.5262 - learning_rate: 2.5000e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 83ms/step - accuracy: 0.8662 - loss: 0.5108 - val_accuracy: 0.8659 - val_loss: 0.5293 - learning_rate: 2.5000e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 80ms/step - accuracy: 0.8633 - loss: 0.5126 - val_accuracy: 0.8666 - val_loss: 0.5203 - learning_rate: 2.5000e-04\n"
          ]
        }
      ],
      "source": [
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=5, horizontal_flip=True, width_shift_range=0.1, height_shift_range=0.1)\n",
        "train_gen = datagen.flow(x_train, y_train, batch_size=64)\n",
        "\n",
        "callbacks=[\n",
        "    tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"cnn_cifar10_best.keras\", save_best_only=True)\n",
        "]\n",
        "\n",
        "hist = cnn.fit(train_gen, epochs=50, validation_data=(x_test, y_test), callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "9e31ce09",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.866599977016449\n",
            "Confusion matrix:\n",
            " [[854  13  23   8   9   0  13   9  55  16]\n",
            " [  2 968   1   0   0   0   2   0   4  23]\n",
            " [ 40   2 800  13  35  21  67  14   3   5]\n",
            " [ 11   6  29 672  53  75 107  23  15   9]\n",
            " [  5   1  23   6 875   4  58  27   1   0]\n",
            " [  2   3  29  99  39 732  53  36   1   6]\n",
            " [  1   2   7   7   4   1 973   2   1   2]\n",
            " [  7   1   6  13  28   9  16 917   1   2]\n",
            " [ 16   6   2   2   4   0   5   0 954  11]\n",
            " [  8  45   2   1   1   1   6   3  12 921]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.85      0.88      1000\n",
            "           1       0.92      0.97      0.95      1000\n",
            "           2       0.87      0.80      0.83      1000\n",
            "           3       0.82      0.67      0.74      1000\n",
            "           4       0.83      0.88      0.85      1000\n",
            "           5       0.87      0.73      0.79      1000\n",
            "           6       0.75      0.97      0.85      1000\n",
            "           7       0.89      0.92      0.90      1000\n",
            "           8       0.91      0.95      0.93      1000\n",
            "           9       0.93      0.92      0.92      1000\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.86     10000\n",
            "weighted avg       0.87      0.87      0.86     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "test_loss, test_acc = cnn.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test accuracy:\", test_acc)\n",
        "\n",
        "y_pred = np.argmax(cnn.predict(x_test, verbose=0), axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(\"Confusion matrix:\\n\", cm)\n",
        "print(classification_report(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6c628f4",
      "metadata": {},
      "source": [
        "No experimento com CIFAR-10, a CNN alcançou **acurácia de ~86,7%**, com desempenho elevado em classes mais fáceis (como `1`, `8` e `9`, todas com precisão/recall >0.90) e maior dificuldade em classes mais ambíguas (`3`, `5` e `6`, com recall entre 0.67–0.73). Esses resultados confirmam a robustez da arquitetura proposta, mas também ressaltam um ponto crítico: **classes minoritárias ou mais difíceis tendem a sofrer em recall**. Essa observação é diretamente análoga ao problema de fraude, onde os casos positivos são raros e o foco deve estar em **maximizar recall sem sacrificar demais a precisão**. Assim, a análise de CIFAR-10 reforça a importância de técnicas como **ajuste de limiar, métricas baseadas em PR AUC e tratamento do desbalanceamento** para melhorar a cobertura de eventos raros, como fraudes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "33b4dad9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Artefatos CNN salvos!\n"
          ]
        }
      ],
      "source": [
        "### 2.4 Salvando artefatos CNN\n",
        "import json, pandas as pd, matplotlib.pyplot as plt\n",
        "cnn.save(\"cnn_cifar10_final.keras\")\n",
        "\n",
        "with open(\"cnn_history.json\",\"w\") as f: json.dump(hist.history,f,indent=2)\n",
        "with open(\"cnn_test_metrics.json\",\"w\") as f: json.dump({\"test_loss\":float(test_loss),\"test_acc\":float(test_acc)},f,indent=2)\n",
        "pd.DataFrame(cm).to_csv(\"cnn_confusion_matrix.csv\",index=False)\n",
        "with open(\"cnn_classification_report.json\",\"w\") as f: json.dump(classification_report(y_true,y_pred,output_dict=True),f,indent=2)\n",
        "\n",
        "plt.plot(hist.history[\"accuracy\"]); plt.plot(hist.history[\"val_accuracy\"]); plt.title(\"Acurácia\"); plt.legend([\"Treino\",\"Val\"]); plt.savefig(\"cnn_curva_acuracia.png\"); plt.close()\n",
        "plt.plot(hist.history[\"loss\"]); plt.plot(hist.history[\"val_loss\"]); plt.title(\"Perda\"); plt.legend([\"Treino\",\"Val\"]); plt.savefig(\"cnn_curva_perda.png\"); plt.close()\n",
        "\n",
        "print(\"✅ Artefatos CNN salvos!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4c01249",
      "metadata": {},
      "source": [
        "## 5) Relação com Detecção de Fraudes (tabular)\n",
        "\n",
        "Embora tenhamos mostrado a engenharia de uma CNN para imagens, o problema de fraude lida majoritariamente com dados tabulares.  \n",
        "Boas práticas indicam:\n",
        "- **MLP (rede densa)** com padronização e regularização é mais apropriada que CNNs.\n",
        "- **Seleção de limiar** é crítica: calibramos para **alta precisão** (minimizar falsos positivos) com o maior recall possível.\n",
        "- Curvas **PR** são mais informativas que ROC em desbalanceamento extremo.\n",
        "\n",
        "A seguir, treinamos um modelo inicial de fraude (pipeline `StandardScaler + MLP(64,32)`), calibramos limiar e avaliamos métricas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "3b8358f3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"threshold_selected\": 0.6273491336540353,\n",
            "  \"test_roc_auc\": 0.9329387136360355,\n",
            "  \"test_pr_auc\": 0.7191904637712943,\n",
            "  \"test_precision_at_tuned\": 0.918918918918919,\n",
            "  \"test_recall_at_tuned\": 0.5396825396825397,\n",
            "  \"test_f1_at_tuned\": 0.68,\n",
            "  \"confusion_matrix\": [\n",
            "    [\n",
            "      5934,\n",
            "      3\n",
            "    ],\n",
            "    [\n",
            "      29,\n",
            "      34\n",
            "    ]\n",
            "  ]\n",
            "}\n",
            "✅ Artefatos fraude salvos!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np, json, joblib, matplotlib.pyplot as plt, pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, roc_auc_score, average_precision_score,\n",
        "    precision_recall_curve, roc_curve,\n",
        "    precision_score, recall_score, f1_score\n",
        ")\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "X, y = make_classification(n_samples=30000, n_features=30, n_informative=12, n_redundant=6,\n",
        "                           n_classes=2, weights=[0.99,0.01], flip_y=0.001,\n",
        "                           class_sep=1.2, random_state=RANDOM_STATE)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,stratify=y,random_state=RANDOM_STATE)\n",
        "\n",
        "pipe = Pipeline([(\"scaler\", StandardScaler()),\n",
        "                 (\"mlp\", MLPClassifier(hidden_layer_sizes=(64,32), activation=\"relu\", solver=\"adam\",\n",
        "                                       alpha=1e-4, batch_size=256, learning_rate_init=1e-3,\n",
        "                                       max_iter=200, early_stopping=True, validation_fraction=0.1,\n",
        "                                       n_iter_no_change=10, random_state=RANDOM_STATE))])\n",
        "pipe.fit(X_train,y_train)\n",
        "\n",
        "proba = pipe.predict_proba(X_test)[:,1]\n",
        "prec, rec, thr = precision_recall_curve(y_test, proba)\n",
        "best_thr, best_rec = 0.5, -1\n",
        "for p,r,t in zip(prec[:-1],rec[:-1],thr):\n",
        "    if p>=0.90 and r>best_rec:\n",
        "        best_thr, best_rec = float(t), r\n",
        "if best_rec<0:\n",
        "    from sklearn.metrics import f1_score\n",
        "    f1s=[f1_score(y_test,(proba>=t).astype(int)) for t in thr]\n",
        "    best_thr=float(thr[int(np.argmax(f1s))])\n",
        "\n",
        "y_pred=(proba>=best_thr).astype(int)\n",
        "metrics={\"threshold_selected\":best_thr,\n",
        "         \"test_roc_auc\":roc_auc_score(y_test,proba),\n",
        "         \"test_pr_auc\":average_precision_score(y_test,proba),\n",
        "         \"test_precision_at_tuned\":precision_score(y_test,y_pred,zero_division=0),\n",
        "         \"test_recall_at_tuned\":recall_score(y_test,y_pred,zero_division=0),\n",
        "         \"test_f1_at_tuned\":f1_score(y_test,y_pred,zero_division=0),\n",
        "         \"confusion_matrix\":confusion_matrix(y_test,y_pred).tolist()}\n",
        "\n",
        "print(json.dumps(metrics,indent=2))\n",
        "\n",
        "# salvar artefatos\n",
        "joblib.dump({\"pipeline\":pipe,\"threshold\":best_thr},\"fraud_mlp_sklearn.joblib\")\n",
        "with open(\"sklearn_metrics.json\",\"w\") as f: json.dump(metrics,f,indent=2)\n",
        "\n",
        "fpr,tpr,_=roc_curve(y_test,proba); plt.plot(fpr,tpr); plt.savefig(\"sklearn_roc_curve.png\"); plt.close()\n",
        "P,R,_=precision_recall_curve(y_test,proba); plt.plot(R,P); plt.savefig(\"sklearn_pr_curve.png\"); plt.close()\n",
        "\n",
        "print(\"✅ Artefatos fraude salvos!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a5c64aa",
      "metadata": {},
      "source": [
        "## 6) Hiperparâmetros\n",
        "\n",
        "A escolha dos hiperparâmetros foi guiada por literatura especializada e práticas consolidadas em aprendizado profundo.  \n",
        "\n",
        "**CNN (CIFAR-10):**  \n",
        "- **Arquitetura:** blocos Conv2D + BatchNorm + ReLU, inspirados em VGG.  \n",
        "- **Dropout:** valores progressivos [0.25, 0.35, 0.45, 0.5] para reduzir overfitting em diferentes profundidades.  \n",
        "- **Regularização L2:** λ = 1e-4 para penalizar pesos excessivos.  \n",
        "- **Pooling:** GlobalAveragePooling substitui Flatten, reduzindo parâmetros e overfitting.  \n",
        "- **Camada densa final:** 128 neurônios com ReLU.  \n",
        "- **Otimizador:** Adam (lr=1e-3), equilibrando robustez e velocidade de convergência.  \n",
        "- **Callbacks:** EarlyStopping (paciente a 10 épocas), ReduceLROnPlateau (fator 0.5) e ModelCheckpoint (melhor modelo salvo).\n",
        "\n",
        "**MLP (Fraude Tabular):**  \n",
        "- **Pré-processamento:** StandardScaler para normalizar variáveis contínuas.  \n",
        "- **Camadas ocultas:** (64, 32) neurônios com ReLU, suficiente para capturar interações sem overfitting.  \n",
        "- **Regularização L2:** λ = 1e-4 para aumentar generalização.  \n",
        "- **Batch size:** 256, equilibrando eficiência e estabilidade do gradiente.  \n",
        "- **Otimizador:** Adam (lr=1e-3).  \n",
        "- **Treinamento:** EarlyStopping (max_iter=200, validação interna 10%).  \n",
        "- **Seleção de limiar:** calibrado para **precisão ≥ 0.90**, garantindo baixa taxa de falsos positivos e buscando o maior recall possível.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24ac0528",
      "metadata": {},
      "source": [
        "## Conclusão\n",
        "\n",
        "- A arquitetura **CNN** para CIFAR-10 confirmou boas práticas de redes convolucionais: uso de BatchNorm, Dropout progressivo, regularização L2 e GlobalAveragePooling resultaram em uma **acurácia de teste de ~86,7%**, consistente com benchmarks.  \n",
        "- Para o domínio de **fraude tabular**, aplicamos um **MLP denso calibrado por limiar**, estratégia mais adequada que CNNs para este tipo de dado. O modelo alcançou **ROC AUC de 0.933, PR AUC de 0.719, precisão ~0.919 e recall ~0.540**, um **trade-off equilibrado** entre minimização de falsos positivos e cobertura de fraudes.  \n",
        "- Esses resultados reforçam a importância da **seleção de limiar** e do uso de **curvas PR** em cenários altamente desbalanceados.  \n",
        "- **Próximos passos** incluem:\n",
        "  - **Engenharia de atributos** baseada em domínio (histórico de transações, dispositivos, geolocalização).  \n",
        "  - **Validação temporal**, mais realista para fraudes, respeitando ordem cronológica.  \n",
        "  - **Modelos tabulares avançados** (XGBoost, LightGBM, TabNet, FT-Transformer) como baseline competitivo.  \n",
        "  - **Calibração probabilística** (Platt scaling, isotonic regression) para melhorar confiabilidade das probabilidades previstas.  "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
